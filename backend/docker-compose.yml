# GPT4Free + Backend Integration
# Executa o servidor g4f Python junto com o backend Node.js

services:
  # Servidor GPT4Free Python
  g4f-server:
    build:
      context: ./g4f-server
      dockerfile: Dockerfile
    container_name: g4f-api
    restart: unless-stopped
    ports:
      - "8080:8080"
    environment:
      - PORT=8080
      - PYTHONUNBUFFERED=1
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    networks:
      - ai-network
    # Recursos limitados para n√£o sobrecarregar
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G

  # Backend Node.js (opcional - para desenvolvimento local)
  backend:
    build:
      context: .
      dockerfile: Dockerfile.backend
    container_name: meu-super-ai-backend
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - PORT=3000
      - G4F_API_URL=http://g4f-server:8080
      - NODE_ENV=production
    depends_on:
      g4f-server:
        condition: service_healthy
    networks:
      - ai-network
    volumes:
      - ./uploads:/app/uploads

networks:
  ai-network:
    driver: bridge

volumes:
  uploads:
